
smlp_logger - INFO - Executing run_smlp.py script: Start

smlp_logger - INFO - Running SMLP in mode "rag": Start

smlp_logger - INFO - Running RAG with base model facebook/rag-token-base, using HuggingFace libs.

smlp_logger - INFO - Starting RAG training

smlp_logger - INFO - Loading dataset (text) ../texts/toy_smlp.json

smlp_logger - INFO - Loading tokenizer and model facebook/rag-token-base

smlp_logger - INFO - Training with: <class 'transformers.models.rag.modeling_rag.RagTokenForGeneration'>

smlp_logger - INFO - Preparing passages and retriever for FAISS

smlp_logger - INFO - Encoding passages for cosine similarity

smlp_logger - INFO - Cosine similarity passage embbeddings and retriever created

smlp_logger - INFO - Loading retriever

smlp_logger - INFO - Tokenizing datasets

smlp_logger - INFO - Creating training_args

smlp_logger - INFO - Creating trainer

smlp_logger - INFO - Training starts

smlp_logger - INFO - Computing loss: start

smlp_logger - INFO - Computing loss: end

smlp_logger - INFO - Computing loss: start

smlp_logger - INFO - Computing loss: end

smlp_logger - INFO - Computing loss: start

smlp_logger - INFO - Computing loss: end

smlp_logger - INFO - Computing loss: start

smlp_logger - INFO - Computing loss: end

smlp_logger - INFO - Training completed

smlp_logger - INFO - Saving model, tokenizer, and retriever to ./test247_model

smlp_logger - INFO - [COSINE] Saving model, tokenizer, and retriever

smlp_logger - INFO - CosineRetriever saved to directory ./test247_model

smlp_logger - INFO - [COSINE] Model, tokenizer, and retriever saved to: ./test247_model

smlp_logger - INFO - Model, tokenizer, and retriever saved to: ./test247_model

smlp_logger - INFO - Starting RAG generation

smlp_logger - INFO - Set random seed to 42 for deterministic generation

smlp_logger - INFO - Loading RAG trained model from: ./test247_model

smlp_logger - INFO - rag_token loaded from config: True

smlp_logger - INFO - Loading model and retriever for cosine similarity from: ./test247_model

smlp_logger - INFO - Model, retriever, and tokenizer loaded successfully (cosine)

smlp_logger - INFO - Generating answers for 1 question(s)

smlp_logger - INFO - ============================================================

smlp_logger - INFO - Processing question 1/1: Who developed SMLP?

smlp_logger - INFO - ============================================================

smlp_logger - INFO - Top Retrieved Passages:

smlp_logger - INFO -   1. SMLP was developed by franz, zurab and konstantin....

smlp_logger - INFO - Generated Answer: SMLP was developed by franz, zurab and konstantin

smlp_logger - INFO - ============================================================

smlp_logger - INFO - Generation complete. Processed 1 questions.

smlp_logger - INFO - Successful: 1

smlp_logger - INFO - Failed: 0

smlp_logger - INFO - ============================================================


smlp_logger - INFO - Saving generated text into ./Test247_toy_smlp_rag_generated.txt

smlp_logger - INFO - Saved retrieved contexts to ./Test247_toy_smlp_rag_retrieved_contexts.json

smlp_logger - INFO - ======================================================================

smlp_logger - INFO - MEMORY CLEANUP: Freeing RAG model memory before loading judge

smlp_logger - INFO - ======================================================================

smlp_logger - INFO - Cleaning up RAG model memory...

smlp_logger - INFO - Memory cleanup complete

smlp_logger - INFO - ======================================================================

smlp_logger - INFO - Running RAG quality evaluation with LLM-as-a-Judge

smlp_logger - INFO - Running LLM judge using model: Qwen/Qwen2.5-1.5B-Instruct

smlp_logger - INFO - Judge results for (training): {'summary': {'num_examples': 1, 'num_valid': 1, 'grounded_rate': 1.0, 'grounded_none_count': 0, 'hallucination_rate': 0.0, 'hallucination_none_count': 0, 'avg_score': 5.0}, 'details': [{'grounded': True, 'hallucination': False, 'score': 5, 'explanation': 'The answer accurately reflects the development team mentioned in the provided context without any fabrication or hallucination.', 'confidence': 'high'}]}

smlp_logger - INFO - LLM judge results written to ./Test247_toy_smlp_llm_training_quality.json

smlp_logger - INFO - Running SMLP in mode "rag": End

smlp_logger - INFO - Executing run_smlp.py script: End
